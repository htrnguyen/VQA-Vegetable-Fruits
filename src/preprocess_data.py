import json
import os
import torch
import torchvision.transforms as transforms
from torch.utils.data import Dataset
from PIL import Image
import unicodedata

# === Cáº¥u hÃ¬nh Ä‘Æ°á»ng dáº«n ===
PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
DATA_DIR = os.path.join(PROJECT_ROOT, "data/processed")
RAW_DIR = os.path.join(PROJECT_ROOT, "data/raw")
VQA_FILE = os.path.join(DATA_DIR, "vqa_data.json")

# === Kiá»ƒm tra & táº¡o thÆ° má»¥c náº¿u chÆ°a tá»“n táº¡i ===
os.makedirs(DATA_DIR, exist_ok=True)


# === Kiá»ƒm tra dá»¯ liá»‡u JSON & lá»c dá»¯ liá»‡u há»£p lá»‡ ===
def validate_data(vqa_data):
    """Kiá»ƒm tra dá»¯ liá»‡u há»£p lá»‡, Ä‘áº£m báº£o má»—i cÃ¢u há»i cÃ³ Ä‘Ãºng 5 cÃ¢u tráº£ lá»i."""
    valid_data = []
    for item in vqa_data:
        try:
            folder_name, image_name = item["image_id"].split("/")
            image_path = os.path.join(RAW_DIR, folder_name, image_name)
            if not os.path.exists(image_path):
                print(f"KhÃ´ng tÃ¬m tháº¥y áº£nh: {image_path}")
                continue
            if len(item["questions"]) != 4:
                continue
            for q in item["questions"]:
                if len(q["answers"]) != 5:
                    continue
            valid_data.append(item)
        except Exception:
            continue
    return valid_data


# === Äá»c file JSON & kiá»ƒm tra dá»¯ liá»‡u ===
try:
    with open(VQA_FILE, "r", encoding="utf-8-sig") as f:
        vqa_data = json.load(f)
    vqa_data = validate_data(vqa_data)
except Exception as e:
    print(f"Lá»—i khi Ä‘á»c file JSON: {str(e)}")
    exit(1)

# === Chuáº©n bá»‹ bá»™ biáº¿n Ä‘á»•i áº£nh (224x224, chuáº©n hÃ³a theo ResNet) ===
transform = transforms.Compose(
    [
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ]
)


# === Táº¡o tá»« Ä‘iá»ƒn cÃ¢u tráº£ lá»i (`answer_dict`) ===
def build_answer_vocab(vqa_data, min_freq=5):
    """XÃ¢y dá»±ng tá»« Ä‘iá»ƒn cÃ¢u tráº£ lá»i, lá»c cÃ¡c cÃ¢u tráº£ lá»i Ã­t xuáº¥t hiá»‡n."""
    answer_freq = {}
    for item in vqa_data:
        for q in item["questions"]:
            for ans in q["answers"]:
                ans = unicodedata.normalize("NFC", ans)
                answer_freq[ans] = answer_freq.get(ans, 0) + 1

    # âœ… Chá»‰ giá»¯ cÃ¢u tráº£ lá»i xuáº¥t hiá»‡n Ã­t nháº¥t `min_freq` láº§n
    filtered_answers = {
        ans: idx
        for idx, (ans, freq) in enumerate(answer_freq.items())
        if freq >= min_freq
    }

    # âœ… ThÃªm "khÃ´ng rÃµ" vÃ o cuá»‘i tá»« Ä‘iá»ƒn
    if "khÃ´ng rÃµ" not in filtered_answers:
        filtered_answers["khÃ´ng rÃµ"] = len(filtered_answers)

    return filtered_answers


answer_dict = build_answer_vocab(vqa_data)


# === XÃ¢y dá»±ng dataset VQA ===
class VQADataset(Dataset):
    def __init__(self, vqa_data, answer_dict, transform=None):
        self.vqa_data = vqa_data
        self.answer_dict = answer_dict
        self.transform = transform
        self.image_dir = RAW_DIR

        # Khá»Ÿi táº¡o tá»« Ä‘iá»ƒn vá»›i token Ä‘áº·c biá»‡t
        self.vocab = {
            "<pad>": 0,
            "<unk>": 1,
        }
        self.build_vocab()
        print(f"ğŸ“Œ Sá»‘ lÆ°á»£ng kÃ½ tá»± trong vocab: {len(self.vocab)}")
        print(f"ğŸ“Œ Má»™t sá»‘ kÃ½ tá»± máº«u trong vocab: {list(self.vocab.items())[:10]}")

    def build_vocab(self):
        """XÃ¢y dá»±ng tá»« Ä‘iá»ƒn kÃ½ tá»± tá»« dá»¯ liá»‡u cÃ¢u há»i."""
        vocab_set = set()
        for item in self.vqa_data:
            for q in item["questions"]:
                # Chuáº©n hÃ³a Unicode cho cÃ¢u há»i
                question = unicodedata.normalize("NFC", q["question"])
                for c in question:
                    vocab_set.add(c)

        # ThÃªm cÃ¡c kÃ½ tá»± vÃ o tá»« Ä‘iá»ƒn
        for i, c in enumerate(sorted(vocab_set)):
            if c not in self.vocab:  # TrÃ¡nh ghi Ä‘Ã¨ lÃªn cÃ¡c token Ä‘áº·c biá»‡t
                self.vocab[c] = len(self.vocab)

    def encode_text(self, text, max_length=32):
        """MÃ£ hÃ³a cÃ¢u há»i thÃ nh chuá»—i sá»‘."""
        # Chuáº©n hÃ³a Unicode cho text Ä‘áº§u vÃ o
        text = unicodedata.normalize("NFC", text)
        # Sá»­ dá»¥ng <unk> (index 1) cho kÃ½ tá»± khÃ´ng cÃ³ trong tá»« Ä‘iá»ƒn
        indices = [self.vocab.get(c, 1) for c in text]

        if len(indices) < max_length:
            # Padding vá»›i <pad> (index 0)
            indices += [0] * (max_length - len(indices))
        else:
            indices = indices[:max_length]

        return torch.tensor(indices, dtype=torch.long)

    def __getitem__(self, idx):
        item = self.vqa_data[idx]

        # LÆ°u Ä‘Æ°á»ng dáº«n áº£nh Ä‘áº§y Ä‘á»§
        image_path = os.path.join(self.image_dir, item["image_id"])

        # Xá»­ lÃ½ áº£nh
        image = Image.open(image_path).convert("RGB")
        if self.transform:
            image = self.transform(image)

        # MÃ£ hÃ³a cÃ¢u há»i thÃ nh tensor
        questions_encoded = torch.stack(
            [self.encode_text(q["question"]) for q in item["questions"]]
        ).to(torch.float32)

        # MÃ£ hÃ³a cÃ¢u tráº£ lá»i
        answers_encoded = []
        for q in item["questions"]:
            ans = [unicodedata.normalize("NFC", a) for a in q["answers"]]
            answer_indices = [
                self.answer_dict.get(a, self.answer_dict["khÃ´ng rÃµ"]) for a in ans
            ]
            answers_encoded.append(torch.tensor(answer_indices))

        return {
            "image": image,
            "image_path": item[
                "image_id"
            ],  # LÆ°u Ä‘Æ°á»ng dáº«n áº£nh gá»‘c Ä‘á»ƒ hiá»ƒn thá»‹ trong Notebook
            "questions": [q["question"] for q in item["questions"]],  # CÃ¢u há»i gá»‘c
            "questions_encoded": questions_encoded,  # CÃ¢u há»i Ä‘Ã£ mÃ£ hÃ³a
            "answers": [q["answers"] for q in item["questions"]],  # CÃ¢u tráº£ lá»i gá»‘c
            "answers_encoded": torch.stack(answers_encoded),  # CÃ¢u tráº£ lá»i Ä‘Ã£ mÃ£ hÃ³a
        }

    def __len__(self):
        """Tráº£ vá» sá»‘ lÆ°á»£ng máº«u dá»¯ liá»‡u"""
        return len(self.vqa_data)


# === Chia dá»¯ liá»‡u train (80%), val (10%), test (10%) ===
train_size = int(0.8 * len(vqa_data))
val_size = int(0.1 * len(vqa_data))
test_size = len(vqa_data) - train_size - val_size

train_dataset = VQADataset(vqa_data[:train_size], answer_dict, transform)
val_dataset = VQADataset(
    vqa_data[train_size : train_size + val_size], answer_dict, transform
)
test_dataset = VQADataset(vqa_data[train_size + val_size :], answer_dict, transform)

# === LÆ°u dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½ ===
torch.save(
    {
        "train": list(train_dataset),
        "val": list(val_dataset),
        "test": list(test_dataset),
        "answer_dict": answer_dict,  # LÆ°u tá»« Ä‘iá»ƒn cÃ¢u tráº£ lá»i
        "vocab": train_dataset.vocab,  # LÆ°u tá»« Ä‘iá»ƒn kÃ½ tá»± cÃ¢u há»i
        "vocab_size": len(train_dataset.vocab),  # Sá»‘ lÆ°á»£ng tá»« trong vocab
        "metadata": {  # LÆ°u metadata Ä‘á»ƒ kiá»ƒm tra nhanh
            "num_train": len(train_dataset.vqa_data),
            "num_val": len(val_dataset.vqa_data),
            "num_test": len(test_dataset.vqa_data),
            "num_answers": len(answer_dict),
            "num_vocab": len(train_dataset.vocab),
        },
    },
    os.path.join(DATA_DIR, "processed_data.pt"),
)

print(f"Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½ vÃ  lÆ°u thÃ nh cÃ´ng!")
print(
    f"Train={len(train_dataset.vqa_data)}, Val={len(val_dataset.vqa_data)}, Test={len(test_dataset.vqa_data)}"
)
print(f"Tá»« vá»±ng: {len(train_dataset.vocab)}, CÃ¢u tráº£ lá»i: {len(answer_dict)}")
