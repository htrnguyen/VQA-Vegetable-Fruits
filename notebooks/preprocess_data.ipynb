{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base directory: c:\\Users\\NGUYEN\\Desktop\\VQA-Vegetable-Fruits\n",
      "Raw directory: c:\\Users\\NGUYEN\\Desktop\\VQA-Vegetable-Fruits\\raw\n",
      "Processed directory: c:\\Users\\NGUYEN\\Desktop\\VQA-Vegetable-Fruits\\processed\n",
      "Data file: c:\\Users\\NGUYEN\\Desktop\\VQA-Vegetable-Fruits\\processed\\vqa_data.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from underthesea import word_tokenize\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm  # Thêm tqdm cho thanh tiến trình\n",
    "\n",
    "# Cấu hình đường dẫn\n",
    "base_dir = os.path.dirname(os.getcwd())\n",
    "raw_dir = os.path.join(base_dir, \"raw\")\n",
    "processed_dir = os.path.join(base_dir, \"processed\")\n",
    "data_file = os.path.join(processed_dir, \"vqa_data.json\")\n",
    "\n",
    "print(f\"Base directory: {base_dir}\")\n",
    "print(f\"Raw directory: {raw_dir}\")\n",
    "print(f\"Processed directory: {processed_dir}\")\n",
    "print(f\"Data file: {data_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kiểm tra dữ liệu thô\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số thư mục: 92\n",
      "\t- 'almond': 66 ảnh\n",
      "\t- 'annona_muricata': 120 ảnh\n",
      "\t- 'apple': 153 ảnh\n",
      "\t- 'apricot': 41 ảnh\n",
      "\t- 'artocarpus_heterophyllus': 120 ảnh\n",
      "\t- 'avocado': 96 ảnh\n",
      "\t- 'banana': 103 ảnh\n",
      "\t- 'bayberry': 72 ảnh\n",
      "\t- 'bergamot_pear': 57 ảnh\n",
      "\t- 'black_currant': 73 ảnh\n",
      "\t- 'black_grape': 40 ảnh\n",
      "\t- 'blood_orange': 96 ảnh\n",
      "\t- 'blueberry': 90 ảnh\n",
      "\t- 'breadfruit': 48 ảnh\n",
      "\t- 'candied_date': 50 ảnh\n",
      "\t- 'carambola': 118 ảnh\n",
      "\t- 'cashew_nut': 58 ảnh\n",
      "\t- 'cherry': 178 ảnh\n",
      "\t- 'cherry_tomato': 162 ảnh\n",
      "\t- 'Chinese_chestnut': 145 ảnh\n",
      "\t- 'citrus': 32 ảnh\n",
      "\t- 'coconut': 58 ảnh\n",
      "\t- 'crown_pear': 56 ảnh\n",
      "\t- 'Dangshan_Pear': 34 ảnh\n",
      "\t- 'dekopon': 92 ảnh\n",
      "\t- 'diospyros_lotus': 48 ảnh\n",
      "\t- 'durian': 123 ảnh\n",
      "\t- 'fig': 110 ảnh\n",
      "\t- 'flat_peach': 136 ảnh\n",
      "\t- 'gandaria': 108 ảnh\n",
      "\t- 'ginseng_fruit': 54 ảnh\n",
      "\t- 'golden_melon': 59 ảnh\n",
      "\t- 'grape': 179 ảnh\n",
      "\t- 'grapefruit': 82 ảnh\n",
      "\t- 'grape_white': 124 ảnh\n",
      "\t- 'green_apple': 54 ảnh\n",
      "\t- 'green_dates': 65 ảnh\n",
      "\t- 'guava': 149 ảnh\n",
      "\t- 'Hami_melon': 45 ảnh\n",
      "\t- 'hawthorn': 91 ảnh\n",
      "\t- 'hazelnut': 43 ảnh\n",
      "\t- 'hickory': 75 ảnh\n",
      "\t- 'honey_dew_melon': 56 ảnh\n",
      "\t- 'housi_pear': 64 ảnh\n",
      "\t- 'juicy_peach': 97 ảnh\n",
      "\t- 'jujube': 91 ảnh\n",
      "\t- 'kiwi_fruit': 147 ảnh\n",
      "\t- 'kumquat': 67 ảnh\n",
      "\t- 'lemon': 54 ảnh\n",
      "\t- 'lime': 39 ảnh\n",
      "\t- 'litchi': 117 ảnh\n",
      "\t- 'longan': 126 ảnh\n",
      "\t- 'loquat': 138 ảnh\n",
      "\t- 'macadamia': 100 ảnh\n",
      "\t- 'mandarin_orange': 52 ảnh\n",
      "\t- 'mango': 141 ảnh\n",
      "\t- 'mangosteen': 131 ảnh\n",
      "\t- 'munlberry': 91 ảnh\n",
      "\t- 'muskmelon': 61 ảnh\n",
      "\t- 'naseberry': 79 ảnh\n",
      "\t- 'navel_orange': 69 ảnh\n",
      "\t- 'nectarine': 134 ảnh\n",
      "\t- 'netted_melon': 44 ảnh\n",
      "\t- 'olive': 55 ảnh\n",
      "\t- 'papaya': 191 ảnh\n",
      "\t- 'passion_fruit': 141 ảnh\n",
      "\t- 'pecans': 172 ảnh\n",
      "\t- 'persimmon': 138 ảnh\n",
      "\t- 'pineapple': 69 ảnh\n",
      "\t- 'pistachio': 120 ảnh\n",
      "\t- 'pitaya': 163 ảnh\n",
      "\t- 'plum': 114 ảnh\n",
      "\t- 'plum-leaf_crab': 73 ảnh\n",
      "\t- 'pomegranate': 150 ảnh\n",
      "\t- 'pomelo': 140 ảnh\n",
      "\t- 'ponkan': 47 ảnh\n",
      "\t- 'prune': 46 ảnh\n",
      "\t- 'rambutan': 105 ảnh\n",
      "\t- 'raspberry': 100 ảnh\n",
      "\t- 'red_grape': 154 ảnh\n",
      "\t- 'salak': 84 ảnh\n",
      "\t- 'sand_pear': 48 ảnh\n",
      "\t- 'sugarcane': 155 ảnh\n",
      "\t- 'sugar_orange': 86 ảnh\n",
      "\t- 'sweetsop': 107 ảnh\n",
      "\t- 'syzygium_jambos': 37 ảnh\n",
      "\t- 'trifoliate_orange': 37 ảnh\n",
      "\t- 'walnuts': 136 ảnh\n",
      "\t- 'wampee': 88 ảnh\n",
      "\t- 'wax_apple': 87 ảnh\n",
      "\t- 'winter_jujube': 76 ảnh\n",
      "\t- 'yacon': 59 ảnh\n",
      "Tổng: 8579 ảnh\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra số lượng folder\n",
    "folders = [f for f in os.listdir(raw_dir) if os.path.isdir(os.path.join(raw_dir, f))]\n",
    "num_folders = len(folders)\n",
    "print(f\"Tổng số thư mục: {num_folders}\")\n",
    "\n",
    "# Kiểm tra số lượng ảnh trong mỗi folder\n",
    "all_images = 0\n",
    "image_counts = {}\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(raw_dir, folder)\n",
    "    images = [\n",
    "        f for f in os.listdir(folder_path) if f.endswith((\".jpg\", \".jpeg\", \".png\"))\n",
    "    ]\n",
    "    image_counts[folder] = len(images)\n",
    "    all_images += len(images)\n",
    "    print(f\"\\t- '{folder}': {len(images)} ảnh\")\n",
    "print(f\"Tổng: {all_images} ảnh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số câu hỏi: 34316\n",
      "Tổng số câu trả lời: 34316\n",
      "Số câu hỏi duy nhất: 806\n",
      "Số câu trả lời duy nhất: 265\n",
      "Danh sách câu hỏi duy nhất: ['nho đen đặt ở đâu?', 'dưa mật có màu gì?', 'Vị trí của nho đỏ là ở đâu?', 'hồng xiêm được đặt ở chỗ nào?', 'Số lượng dứa là bao nhiêu?', 'Bạn thấy nho đỏ ở đâu?', 'Vị trí của chanh xanh là ở đâu?', 'Có bao nhiêu lê vương miện?', 'Màu sắc của táo tàu là gì?', 'Số lượng thanh long là bao nhiêu?']\n",
      "Danh sách câu trả lời duy nhất: ['mơ', 'ngón tay', '4', 'lá', 'bưởi chùm', 'hồng', 'đỏ', 'trắng tím', 'táo chua', 'đất']\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra số lượng câu hỏi và câu trả lời từ file JSON\n",
    "with open(data_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    vqa_data = json.load(f)\n",
    "\n",
    "num_questions = 0\n",
    "num_answers = 0\n",
    "question_set = set()  # Các câu hỏi duy nhất\n",
    "answer_set = set()  # Các câu trả lời duy nhất\n",
    "\n",
    "for entry in vqa_data:\n",
    "    questions = entry.get(\"questions\", [])\n",
    "    num_questions += len(questions)\n",
    "    num_answers += len(questions)  # Mỗi câu hỏi có 1 câu trả lời\n",
    "    for q in questions:\n",
    "        question_set.add(q[\"question\"])\n",
    "        answer_set.add(q[\"correct_answer\"])\n",
    "\n",
    "print(f\"Tổng số câu hỏi: {num_questions}\")\n",
    "print(f\"Tổng số câu trả lời: {num_answers}\")\n",
    "print(f\"Số câu hỏi duy nhất: {len(question_set)}\")\n",
    "print(f\"Số câu trả lời duy nhất: {len(answer_set)}\")\n",
    "print(\"Danh sách câu hỏi duy nhất:\", list(question_set)[:10])\n",
    "print(\"Danh sách câu trả lời duy nhất:\", list(answer_set)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiền xử lý\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Danh sách từ ghép cần giữ nguyên\n",
    "fruit_names = [\n",
    "    \"hạnh nhân\",\n",
    "    \"mãng cầu xiêm\",\n",
    "    \"táo\",\n",
    "    \"mơ\",\n",
    "    \"mít\",\n",
    "    \"bơ\",\n",
    "    \"chuối\",\n",
    "    \"dâu rừng\",\n",
    "    \"cam bergamot\",\n",
    "    \"lý chua đen\",\n",
    "    \"nho đen\",\n",
    "    \"cam đỏ\",\n",
    "    \"việt quất\",\n",
    "    \"sa kê\",\n",
    "    \"chà là sấy\",\n",
    "    \"khế\",\n",
    "    \"hạt điều\",\n",
    "    \"anh đào\",\n",
    "    \"cà chua bi\",\n",
    "    \"hạt dẻ\",\n",
    "    \"cam quýt\",\n",
    "    \"dừa\",\n",
    "    \"lê vương miện\",\n",
    "    \"lê đường sơn\",\n",
    "    \"cam dekopon\",\n",
    "    \"thị\",\n",
    "    \"sầu riêng\",\n",
    "    \"sung\",\n",
    "    \"đào\",\n",
    "    \"quả thanh trà\",\n",
    "    \"nhân sâm\",\n",
    "    \"dưa vàng\",\n",
    "    \"nho\",\n",
    "    \"nho trắng\",\n",
    "    \"bưởi chùm\",\n",
    "    \"táo xanh\",\n",
    "    \"táo xanh\",\n",
    "    \"ổi\",\n",
    "    \"dưa hami\",\n",
    "    \"táo gai\",\n",
    "    \"hạt phỉ\",\n",
    "    \"hồ đào\",\n",
    "    \"dưa mật\",\n",
    "    \"lê housi\",\n",
    "    \"đào mọng\",\n",
    "    \"táo tàu\",\n",
    "    \"kiwi\",\n",
    "    \"quất\",\n",
    "    \"chanh vàng\",\n",
    "    \"chanh xanh\",\n",
    "    \"vải\",\n",
    "    \"nhãn\",\n",
    "    \"tỳ bà\",\n",
    "    \"hạt mắc ca\",\n",
    "    \"quýt\",\n",
    "    \"xoài\",\n",
    "    \"măng cụt\",\n",
    "    \"dâu tằm\",\n",
    "    \"dưa lưới\",\n",
    "    \"hồng xiêm\",\n",
    "    \"cam rốn\",\n",
    "    \"xuân đào\",\n",
    "    \"dưa lưới\",\n",
    "    \"ô liu\",\n",
    "    \"đu đủ\",\n",
    "    \"chanh dây\",\n",
    "    \"hạt pecan\",\n",
    "    \"hồng\",\n",
    "    \"dứa\",\n",
    "    \"hạt dẻ cười\",\n",
    "    \"thanh long\",\n",
    "    \"mận\",\n",
    "    \"táo chua\",\n",
    "    \"lựu\",\n",
    "    \"bưởi\",\n",
    "    \"quýt ponkan\",\n",
    "    \"mận khô\",\n",
    "    \"chôm chôm\",\n",
    "    \"phúc bồn tử\",\n",
    "    \"nho đỏ\",\n",
    "    \"da rắn\",\n",
    "    \"lê cát\",\n",
    "    \"mía\",\n",
    "    \"cam đường\",\n",
    "    \"mãng cầu\",\n",
    "    \"mận\",\n",
    "    \"cam ba lá\",\n",
    "    \"hạt óc chó\",\n",
    "    \"hồng bì\",\n",
    "    \"mận đá\",\n",
    "    \"hồng táo\",\n",
    "    \"củ sắn\",\n",
    "]\n",
    "special_phrases = [\"không rõ\", \"bao nhiêu\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chuẩn hóa dữ liệu văn bản và tạo ánh xạ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang chuẩn hóa dữ liệu văn bản...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing entries: 100%|██████████| 8579/8579 [00:00<00:00, 239141.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã chuẩn hóa và lưu: c:\\Users\\NGUYEN\\Desktop\\VQA-Vegetable-Fruits\\processed\\vqa_data_normalized.json\n",
      "Đã tạo file ánh xạ: c:\\Users\\NGUYEN\\Desktop\\VQA-Vegetable-Fruits\\processed\\index_mapping.json\n",
      "Tổng số ảnh: 8579\n",
      "Tổng số câu hỏi/đáp án: 34316\n"
     ]
    }
   ],
   "source": [
    "with open(data_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    vqa_data = json.load(f)\n",
    "\n",
    "# Chuẩn hóa về chữ thường và tạo ánh xạ với thanh tiến trình\n",
    "index_mapping = {\"image_indices\": {}, \"qa_indices\": {}}\n",
    "image_idx = 0\n",
    "qa_idx = 0\n",
    "\n",
    "print(\"Đang chuẩn hóa dữ liệu văn bản...\")\n",
    "for entry in tqdm(vqa_data, desc=\"Processing entries\"):\n",
    "    image_id = entry[\"image_id\"]\n",
    "    index_mapping[\"image_indices\"][str(image_idx)] = image_id\n",
    "    for q in entry[\"questions\"]:\n",
    "        q[\"question\"] = q[\"question\"].lower()\n",
    "        q[\"correct_answer\"] = q[\"correct_answer\"].lower()\n",
    "        index_mapping[\"qa_indices\"][str(qa_idx)] = {\n",
    "            \"image_idx\": image_idx,\n",
    "            \"question\": q[\"question\"],\n",
    "            \"answer\": q[\"correct_answer\"],\n",
    "        }\n",
    "        qa_idx += 1\n",
    "    image_idx += 1\n",
    "\n",
    "# Lưu file\n",
    "normalized_data_file = os.path.join(processed_dir, \"vqa_data_normalized.json\")\n",
    "with open(normalized_data_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(vqa_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "mapping_file = os.path.join(processed_dir, \"index_mapping.json\")\n",
    "with open(mapping_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(index_mapping, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Đã chuẩn hóa và lưu: {normalized_data_file}\")\n",
    "print(f\"Đã tạo file ánh xạ: {mapping_file}\")\n",
    "print(f\"Tổng số ảnh: {len(index_mapping['image_indices'])}\")\n",
    "print(f\"Tổng số câu hỏi/đáp án: {len(index_mapping['qa_indices'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tiền xử lý ảnh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang xử lý 8579 ảnh...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 8579/8579 [00:23<00:00, 364.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã xử lý và lưu: images.pt\n",
      "Kích thước tensor ảnh: torch.Size([8579, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "image_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "images = []\n",
    "image_ids = []\n",
    "\n",
    "folders = [f for f in os.listdir(raw_dir) if os.path.isdir(os.path.join(raw_dir, f))]\n",
    "total_images = sum(\n",
    "    len(\n",
    "        [\n",
    "            f\n",
    "            for f in os.listdir(os.path.join(raw_dir, folder))\n",
    "            if f.endswith((\".jpg\", \".jpeg\", \".png\"))\n",
    "        ]\n",
    "    )\n",
    "    for folder in folders\n",
    ")\n",
    "\n",
    "print(f\"Đang xử lý {total_images} ảnh...\")\n",
    "with tqdm(total=total_images, desc=\"Processing images\") as pbar:\n",
    "    for folder in folders:\n",
    "        folder_path = os.path.join(raw_dir, folder)\n",
    "        for img_file in os.listdir(folder_path):\n",
    "            if img_file.endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "                img_path = os.path.join(folder_path, img_file)\n",
    "                img = Image.open(img_path).convert(\"RGB\")\n",
    "                img_tensor = image_transform(img)\n",
    "                images.append(img_tensor)\n",
    "                image_ids.append(f\"{folder}/{img_file}\")\n",
    "                pbar.update(1)\n",
    "\n",
    "# Gộp thành tensor lớn\n",
    "images_tensor = torch.stack(images)  # [8579, 3, 224, 224]\n",
    "torch.save(\n",
    "    {\"images\": images_tensor, \"image_ids\": image_ids},\n",
    "    os.path.join(processed_dir, \"images.pt\"),\n",
    ")\n",
    "\n",
    "print(f\"Đã xử lý và lưu: images.pt\")\n",
    "print(f\"Kích thước tensor ảnh: {images_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tiền xử lý văn bản (giữ từ ghép)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã cập nhật và lưu vocab.pt mới. Kích thước từ điển: 264\n",
      "Đang tokenize và padding dữ liệu văn bản...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing QA: 100%|██████████| 34316/34316 [00:16<00:00, 2124.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu questions.pt: torch.Size([34316, 7])\n",
      "Đã lưu answers.pt: torch.Size([34316, 3])\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer\n",
    "def custom_tokenizer(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    result = []\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        # Kiểm tra từ ghép dài nhất có thể\n",
    "        found_compound = False\n",
    "        for length in range(\n",
    "            min(4, len(tokens) - i), 0, -1\n",
    "        ):  # Kiểm tra từ 4 từ xuống 1 từ\n",
    "            compound = \" \".join(tokens[i : i + length])\n",
    "            if compound in fruit_names or compound in special_phrases:\n",
    "                result.append(compound)\n",
    "                i += length\n",
    "                found_compound = True\n",
    "                break\n",
    "        if not found_compound:\n",
    "            result.append(tokens[i])\n",
    "            i += 1\n",
    "    return result\n",
    "\n",
    "\n",
    "# Load dữ liệu\n",
    "with open(data_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    vqa_data = json.load(f)\n",
    "\n",
    "questions = [q[\"question\"] for entry in vqa_data for q in entry[\"questions\"]]\n",
    "answers = [q[\"correct_answer\"] for entry in vqa_data for q in entry[\"questions\"]]\n",
    "\n",
    "\n",
    "# Xây dựng từ điển\n",
    "def yield_tokens(data_iter):\n",
    "    for text in data_iter:\n",
    "        yield custom_tokenizer(text)\n",
    "\n",
    "\n",
    "vocab = build_vocab_from_iterator(\n",
    "    yield_tokens(questions + answers), specials=[\"<pad>\", \"<unk>\"]\n",
    ")\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "# Ép buộc thêm các từ ghép bị thiếu\n",
    "for fruit in fruit_names:\n",
    "    if fruit not in vocab:\n",
    "        vocab.append_token(fruit)\n",
    "for phrase in special_phrases:\n",
    "    if phrase not in vocab:\n",
    "        vocab.append_token(phrase)\n",
    "\n",
    "# Lưu vocab mới\n",
    "torch.save(vocab, os.path.join(processed_dir, \"vocab.pt\"))\n",
    "print(f\"Đã cập nhật và lưu vocab.pt mới. Kích thước từ điển: {len(vocab)}\")\n",
    "\n",
    "# Tạo tensor cho questions.pt và answers.pt với thanh tiến trình\n",
    "question_sequences = []\n",
    "answer_sequences = []\n",
    "\n",
    "print(\"Đang tokenize và padding dữ liệu văn bản...\")\n",
    "for q, a in tqdm(zip(questions, answers), total=len(questions), desc=\"Tokenizing QA\"):\n",
    "    q_seq = torch.tensor(vocab(custom_tokenizer(q)))\n",
    "    a_seq = torch.tensor(vocab(custom_tokenizer(a)))\n",
    "    question_sequences.append(q_seq)\n",
    "    answer_sequences.append(a_seq)\n",
    "\n",
    "# Padding\n",
    "max_q_len = max(len(seq) for seq in question_sequences)\n",
    "max_a_len = max(len(seq) for seq in answer_sequences)\n",
    "question_padded = torch.nn.utils.rnn.pad_sequence(\n",
    "    question_sequences, batch_first=True, padding_value=vocab[\"<pad>\"]\n",
    ")\n",
    "answer_padded = torch.nn.utils.rnn.pad_sequence(\n",
    "    answer_sequences, batch_first=True, padding_value=vocab[\"<pad>\"]\n",
    ")\n",
    "\n",
    "question_padded = question_padded[:, :max_q_len]\n",
    "answer_padded = answer_padded[:, :max_a_len]\n",
    "\n",
    "# Lưu tensor\n",
    "torch.save(question_padded, os.path.join(processed_dir, \"questions.pt\"))\n",
    "torch.save(answer_padded, os.path.join(processed_dir, \"answers.pt\"))\n",
    "print(f\"Đã lưu questions.pt: {question_padded.shape}\")\n",
    "print(f\"Đã lưu answers.pt: {answer_padded.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chia dữ liệu train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang chia dữ liệu train/val/test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting folders: 100%|██████████| 92/92 [00:00<00:00, 12976.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train indices: 6826 ảnh\n",
      "Val indices: 816 ảnh\n",
      "Test indices: 937 ảnh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Tạo danh sách chỉ số ảnh theo thư mục\n",
    "folder_to_indices = defaultdict(list)\n",
    "for idx, image_id in index_mapping[\"image_indices\"].items():\n",
    "    folder = image_id.split(\"/\")[0]\n",
    "    folder_to_indices[folder].append(int(idx))\n",
    "\n",
    "# Chia đều từng thư mục\n",
    "train_indices = []\n",
    "val_indices = []\n",
    "test_indices = []\n",
    "\n",
    "print(\"Đang chia dữ liệu train/val/test...\")\n",
    "for folder, indices in tqdm(folder_to_indices.items(), desc=\"Splitting folders\"):\n",
    "    np.random.shuffle(indices)  # Xáo trộn ngẫu nhiên\n",
    "    n = len(indices)\n",
    "    train_n = int(0.8 * n)  # 80%\n",
    "    val_n = int(0.1 * n)  # 10%\n",
    "    test_n = n - train_n - val_n  # 10% còn lại\n",
    "\n",
    "    train_indices.extend(indices[:train_n])\n",
    "    val_indices.extend(indices[train_n : train_n + val_n])\n",
    "    test_indices.extend(indices[train_n + val_n :])\n",
    "\n",
    "# Sắp xếp lại để đảm bảo thứ tự\n",
    "train_indices.sort()\n",
    "val_indices.sort()\n",
    "test_indices.sort()\n",
    "\n",
    "# Lưu chỉ số\n",
    "torch.save(torch.tensor(train_indices), os.path.join(processed_dir, \"train_indices.pt\"))\n",
    "torch.save(torch.tensor(val_indices), os.path.join(processed_dir, \"val_indices.pt\"))\n",
    "torch.save(torch.tensor(test_indices), os.path.join(processed_dir, \"test_indices.pt\"))\n",
    "\n",
    "print(f\"Train indices: {len(train_indices)} ảnh\")\n",
    "print(f\"Val indices: {len(val_indices)} ảnh\")\n",
    "print(f\"Test indices: {len(test_indices)} ảnh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kiểm tra dữ liệu đã xử lý"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kích thước tensor ảnh: torch.Size([8579, 3, 224, 224])\n",
      "Kích thước tensor câu hỏi: torch.Size([34316, 7])\n",
      "Kích thước tensor đáp án: torch.Size([34316, 3])\n",
      "Kích thước từ điển: 264\n",
      "Số ảnh train: 6826\n",
      "Số ảnh val: 816\n",
      "Số ảnh test: 937\n",
      "Tổng số ảnh: 8579\n",
      "\n",
      "Danh sách từ vựng:\n",
      "0: <pad>\n",
      "1: <unk>\n",
      "2: ?\n",
      "3: là\n",
      "4: gì\n",
      "5: quả\n",
      "6: ở\n",
      "7: bao nhiêu\n",
      "8: có\n",
      "9: đâu\n",
      "10: đây\n",
      "11: không rõ\n",
      "12: đặt\n",
      "13: của\n",
      "14: màu\n",
      "15: số lượng\n",
      "16: màu sắc\n",
      "17: cây\n",
      "18: đỏ\n",
      "19: xanh\n",
      "20: vị trí\n",
      "21: vàng\n",
      "22: nâu\n",
      "23: 2\n",
      "24: bàn\n",
      "25: 1\n",
      "26: táo\n",
      "27: này\n",
      "28: nho\n",
      "29: 3\n",
      "30: đu đủ\n",
      "31: anh đào\n",
      "32: đào\n",
      "33: hồng\n",
      "34: thanh long\n",
      "35: mận\n",
      "36: mía\n",
      "37: ổi\n",
      "38: kiwi\n",
      "39: đĩa\n",
      "40: hạt dẻ\n",
      "41: nho đỏ\n",
      "42: bưởi\n",
      "43: chanh dây\n",
      "44: xoài\n",
      "45: được\n",
      "46: cam\n",
      "47: tỳ bà\n",
      "48: chỗ\n",
      "49: nào\n",
      "50: hạt pecan\n",
      "51: măng cụt\n",
      "52: nhãn\n",
      "53: xuân đào\n",
      "54: vải\n",
      "55: sầu riêng\n",
      "56: cà chua bi\n",
      "57: hạt dẻ cười\n",
      "58: mít\n",
      "59: tên\n",
      "60: khế\n",
      "61: táo tàu\n",
      "62: mãng cầu xiêm\n",
      "63: nho trắng\n",
      "64: mãng cầu\n",
      "65: sung\n",
      "66: chôm chôm\n",
      "67: 4\n",
      "68: dưa lưới\n",
      "69: chuối\n",
      "70: hạt óc chó\n",
      "71: phúc bồn tử\n",
      "72: táo xanh\n",
      "73: tím\n",
      "74: bơ\n",
      "75: cam đỏ\n",
      "76: lựu\n",
      "77: cam dekopon\n",
      "78: táo gai\n",
      "79: dâu tằm\n",
      "80: việt quất\n",
      "81: hồng bì\n",
      "82: cam đường\n",
      "83: mận đá\n",
      "84: da rắn\n",
      "85: bưởi chùm\n",
      "86: hồng xiêm\n",
      "87: quả thanh trà\n",
      "88: trong\n",
      "89: hạt mắc ca\n",
      "90: hồ đào\n",
      "91: đào mọng\n",
      "92: lý chua đen\n",
      "93: dâu rừng\n",
      "94: ảnh\n",
      "95: bát\n",
      "96: cam rốn\n",
      "97: dứa\n",
      "98: quất\n",
      "99: hạnh nhân\n",
      "100: rổ\n",
      "101: 5\n",
      "102: củ sắn\n",
      "103: lê housi\n",
      "104: dừa\n",
      "105: dưa vàng\n",
      "106: hạt điều\n",
      "107: ô liu\n",
      "108: dưa mật\n",
      "109: lê vương miện\n",
      "110: chanh vàng\n",
      "111: nhân sâm\n",
      "112: hộp\n",
      "113: quýt\n",
      "114: đen\n",
      "115: lê cát\n",
      "116: sa kê\n",
      "117: quýt ponkan\n",
      "118: bạn\n",
      "119: thấy\n",
      "120: táo chua\n",
      "121: dưa hami\n",
      "122: hồng táo\n",
      "123: thị\n",
      "124: hạt phỉ\n",
      "125: cam bergamot\n",
      "126: 6\n",
      "127: 7\n",
      "128: mơ\n",
      "129: nho đen\n",
      "130: pecan\n",
      "131: chanh xanh\n",
      "132: mận khô\n",
      "133: chà là sấy\n",
      "134: cam ba lá\n",
      "135: bi đặt\n",
      "136: cà chua\n",
      "137: trắng\n",
      "138: chó\n",
      "139: óc\n",
      "140: lê đường sơn\n",
      "141: lựu đặt\n",
      "142: tay\n",
      "143: lá\n",
      "144: ca\n",
      "145: mắc\n",
      "146: đất\n",
      "147: lựu là\n",
      "148: cam quýt\n",
      "149: ngoài\n",
      "150: lê\n",
      "151: 10\n",
      "152: giỏ\n",
      "153: nhạt\n",
      "154: kem\n",
      "155: chua đặt\n",
      "156: chà\n",
      "157: đồng\n",
      "158: 8\n",
      "159: túi\n",
      "160: táo đặt\n",
      "161: khay\n",
      "162: 12\n",
      "163: cành\n",
      "164: mặt phẳng\n",
      "165: 9\n",
      "166: trời\n",
      "167: giấy\n",
      "168: mấy\n",
      "169: vườn\n",
      "170: hình\n",
      "171: loại\n",
      "172: ruộng\n",
      "173: thớt\n",
      "174: như thế nào\n",
      "175: dẹt\n",
      "176: gỗ\n",
      "177: thanh\n",
      "178: thùng\n",
      "179: trà\n",
      "180: chiếu\n",
      "181: roi\n",
      "182: đếm\n",
      "183: đống\n",
      "184: chậu\n",
      "185: khăn\n",
      "186: cốc\n",
      "187: vỏ\n",
      "188: 13\n",
      "189: 11\n",
      "190: 15\n",
      "191: đá\n",
      "192: bánh\n",
      "193: chanh\n",
      "194: dưa\n",
      "195: nồi\n",
      "196: sàn\n",
      "197: đang\n",
      "198: 14\n",
      "199: bình\n",
      "200: cỏ\n",
      "201: dưới\n",
      "202: ly\n",
      "203: bao\n",
      "204: nơi\n",
      "205: thước\n",
      "206: xe\n",
      "207: 16\n",
      "208: 20\n",
      "209: chua\n",
      "210: cà\n",
      "211: cân\n",
      "212: giàn\n",
      "213: lọ\n",
      "214: mặt\n",
      "215: thìa\n",
      "216: 17\n",
      "217: báo\n",
      "218: bồn\n",
      "219: chảo\n",
      "220: cạnh\n",
      "221: kệ\n",
      "222: lưới\n",
      "223: mâm\n",
      "224: nền\n",
      "225: rửa\n",
      "226: sách\n",
      "227: treo\n",
      "228: xe tải\n",
      "229: xôi\n",
      "230: đường\n",
      "231: 28\n",
      "232: biển\n",
      "233: bãi\n",
      "234: bìa\n",
      "235: bản đồ\n",
      "236: chồng\n",
      "237: củ\n",
      "238: dĩa\n",
      "239: dẻ\n",
      "240: gandaria\n",
      "241: ghế\n",
      "242: khuôn\n",
      "243: khô\n",
      "244: muỗng\n",
      "245: ngón\n",
      "246: nilon\n",
      "247: pepino\n",
      "248: phím\n",
      "249: rơm\n",
      "250: thau\n",
      "251: trên\n",
      "252: tươi\n",
      "253: tối\n",
      "254: ván\n",
      "255: vỉa hè\n",
      "256: xám\n",
      "257: xô\n",
      "258: điện thoại\n",
      "259: đó\n",
      "260: đầu\n",
      "261: đậu\n",
      "262: đế\n",
      "263: ống\n",
      "\n",
      "Các từ ghép tên trái cây không có trong vocab:\n",
      "Tất cả 92 tên trái cây đều có trong vocab!\n",
      "\n",
      "Các cụm từ đặc biệt không có trong vocab:\n",
      "Tất cả cụm từ đặc biệt đều có trong vocab!\n"
     ]
    }
   ],
   "source": [
    "# Load dữ liệu\n",
    "images_data = torch.load(os.path.join(processed_dir, \"images.pt\"))\n",
    "questions = torch.load(os.path.join(processed_dir, \"questions.pt\"))\n",
    "answers = torch.load(os.path.join(processed_dir, \"answers.pt\"))\n",
    "vocab = torch.load(os.path.join(processed_dir, \"vocab.pt\"))\n",
    "train_indices = torch.load(os.path.join(processed_dir, \"train_indices.pt\"))\n",
    "val_indices = torch.load(os.path.join(processed_dir, \"val_indices.pt\"))\n",
    "test_indices = torch.load(os.path.join(processed_dir, \"test_indices.pt\"))\n",
    "\n",
    "# Kiểm tra kích thước dữ liệu\n",
    "print(f\"Kích thước tensor ảnh: {images_data['images'].shape}\")\n",
    "print(f\"Kích thước tensor câu hỏi: {questions.shape}\")\n",
    "print(f\"Kích thước tensor đáp án: {answers.shape}\")\n",
    "print(f\"Kích thước từ điển: {len(vocab)}\")\n",
    "print(f\"Số ảnh train: {len(train_indices)}\")\n",
    "print(f\"Số ảnh val: {len(val_indices)}\")\n",
    "print(f\"Số ảnh test: {len(test_indices)}\")\n",
    "print(\n",
    "    f\"Tổng số ảnh: {len(train_indices) + len(val_indices) + len(test_indices)}\"\n",
    ")\n",
    "\n",
    "# Kiểm tra vocab\n",
    "vocab_list = vocab.get_itos()  # Lấy danh sách từ vựng\n",
    "print(\"\\nDanh sách từ vựng:\")\n",
    "for idx, token in enumerate(vocab_list):\n",
    "    print(f\"{idx}: {token}\")\n",
    "\n",
    "# Kiểm tra từ ghép tên trái cây\n",
    "missing_fruits = [fruit for fruit in fruit_names if fruit not in vocab_list]\n",
    "print(\"\\nCác từ ghép tên trái cây không có trong vocab:\")\n",
    "if missing_fruits:\n",
    "    for fruit in missing_fruits:\n",
    "        print(f\"- {fruit}\")\n",
    "else:\n",
    "    print(\"Tất cả 92 tên trái cây đều có trong vocab!\")\n",
    "\n",
    "# Kiểm tra cụm từ đặc biệt\n",
    "missing_phrases = [phrase for phrase in special_phrases if phrase not in vocab_list]\n",
    "print(\"\\nCác cụm từ đặc biệt không có trong vocab:\")\n",
    "if missing_phrases:\n",
    "    for phrase in missing_phrases:\n",
    "        print(f\"- {phrase}\")\n",
    "else:\n",
    "    print(\"Tất cả cụm từ đặc biệt đều có trong vocab!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
